
==================================================
File: I:\Constitution-AI\backend\chatbot.py
==================================================

import openai
import requests
from sentence_transformers import SentenceTransformer
from vector_store import VectorStoreManager
import json

class LegalRAGChatbot:
    def __init__(self, 
                 embedding_model_name='all-MiniLM-L6-v2',
                 openrouter_api_key="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",
                 model_name="openai/gpt-4o-mini"):
        self.vector_store = VectorStoreManager(embedding_model_name)
        self.api_key = openrouter_api_key
        self.model_name = model_name
        self.api_url = "https://openrouter.ai/api/v1/chat/completions"
        
        # Initialize test data if knowledge base is empty
        if self.vector_store.get_document_count() == 0:
            self.initialize_test_data()

    def initialize_test_data(self):
        """Initialize the knowledge base with test legal documents"""
        test_documents = [
            """According to Section 302 of Indian Penal Code (IPC), whoever commits murder shall be punished with death, 
            or imprisonment for life, and shall also be liable to fine.""",
            
            """Under Section 304A of IPC, whoever causes the death of any person by doing any rash or negligent act 
            not amounting to culpable homicide, shall be punished with imprisonment of either description for a term 
            which may extend to two years, or with fine, or with both.""",
            
            """As per Section 375 of IPC, rape is defined as specific acts against a woman without her consent or will, 
            and is punishable under Section 376 with rigorous imprisonment of either description for a term which shall 
            not be less than ten years, but which may extend to imprisonment for life.""",
            
            """According to Section 420 of IPC, whoever cheats and thereby dishonestly induces the person deceived to 
            deliver any property to any person shall be punished with imprisonment of either description for a term 
            which may extend to seven years, and shall also be liable to fine.""",
            
            """The Right to Information Act, 2005 mandates timely response to citizen requests for government information. 
            It is an initiative taken by Department of Personnel and Training, Ministry of Personnel, Public Grievances 
            and Pensions to provide a RTI Portal Gateway to the citizens for quick search of information."""
        ]
        
        print("üìö Initializing knowledge base with test legal documents...")
        self.vector_store.add_documents(test_documents)
        print(f"‚úÖ Added {len(test_documents)} test documents to the knowledge base.")
        return len(test_documents)

    def generate_response(self, query, context_docs):
        """Generate RAG-based response using OpenRouter"""
        if not context_docs:
            return "No relevant legal documents found. Please refine your query."

        # Validate context retrieval success
        if not any(isinstance(doc, str) and doc.strip() for doc in context_docs):
            return "Error: Retrieved context is empty or invalid."

        # Combine retrieved context with query
        prompt = self._create_prompt(query, context_docs)
        
        # Make OpenRouter API request
        headers = {"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"}
        payload = {
            "model": self.model_name,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.7,
            "max_tokens": 512,
            "top_p": 0.9,
            "frequency_penalty": 0,
            "presence_penalty": 0
        }

        try:
            response = requests.post(self.api_url, headers=headers, json=payload)
            response.raise_for_status()  # Raise an error for bad responses

            # Validate API response
            response_data = response.json()
            if "choices" not in response_data or not response_data["choices"]:
                return "Error: Unexpected API response format."

            response_text = response_data["choices"][0]["message"]["content"]
            
            # Ensure the response is valid JSON
            try:
                json_output = json.loads(response_text)
                if "answer" in json_output and "basis" in json_output:
                    return json_output["answer"]
                else:
                    return "Error: Response JSON is missing required keys."
            except json.JSONDecodeError:
                return "Error: OpenRouter response is not valid JSON."

        except requests.exceptions.RequestException as e:
            return f"API request failed: {str(e)}"

    def _create_prompt(self, query, context_docs):
        """Create structured prompt with legal context"""
        max_context_length = 1500
        combined_context = ' '.join(context_docs)
        if len(combined_context) > max_context_length:
            combined_context = combined_context[:max_context_length] + "..."

        # OpenRouter GPT-4o-mini chat format
        prompt = f"""
        You are an AI-based Indian Law Advisor that provides accurate legal information strictly based on the provided context. 
        Your responses must be in JSON format containing:
        1. 'answer' - Clear legal advice based on context.
        2. 'basis' - Array of EXACT QUOTES from provided context that form the foundation of the answer.

        Context: {combined_context}

        User Query: {query}

        Expected Response Format:
        {{ 
          "answer": "Your legal advice...",
          "basis": [
            "Exact quote 1 from context...",
            "Exact quote 2 from context..."
          ]
        }}
        -Important
         1. you must provide response in the valid JSON format.
         2. give exact quotes of laws as the basis of the answer.
        """
        return prompt


def interactive_chat():
    """Interactive chat with the legal RAG chatbot"""
    chatbot = LegalRAGChatbot()
    print("count",chatbot.vector_store.get_document_count())
    print("\nüîπ Welcome to the Legal RAG Chatbot! Type 'exit' to quit.\n")
    
    # Display knowledge base status
    doc_count = chatbot.vector_store.get_document_count()
    print(f"üìö Knowledge base loaded with {doc_count} documents.\n")
    
    print("You can ask questions about:")
    print("- IPC Sections (302, 304A, 375, 420)")
    print("- Right to Information Act")
    print("- Basic legal rights and procedures\n")

    while True:
        query = input("üë§ You: ")
        if query.lower() == "exit":
            print("\nüëã Exiting chat. Have a great day!\n")
            break

        context_docs = chatbot.vector_store.search(query)
        
        if not context_docs:
            print("ü§ñ Bot: I apologize, but I couldn't find relevant information in my knowledge base to answer your question accurately. Please try asking about Indian criminal law, RTI, or basic legal rights.\n")
            continue

        response = chatbot.generate_response(query, context_docs)
        print(f"ü§ñ Bot: {response}\n")


def test_chatbot():
    """Test function to verify chatbot functionality"""
    chatbot = LegalRAGChatbot()

    # Test Case 1: Valid Query with Context
    query1 = "What are the legal rights of tenants in India?"
    context_docs1 = [
        "According to the Rent Control Act, tenants have the right to a fair rental price and cannot be evicted without proper notice.",
        "Section 14 of the Delhi Rent Control Act states that landlords can only evict tenants under specific circumstances."
    ]
    
    response1 = chatbot.generate_response(query1, context_docs1)
    print("\n‚úÖ Test Case 1 Passed" if "Error" not in response1 else "‚ùå Test Case 1 Failed")

    # Test Case 2: Valid Query but Empty Context
    query2 = "What is the legal process for filing an FIR?"
    context_docs2 = []
    
    response2 = chatbot.generate_response(query2, context_docs2)
    print("\n‚úÖ Test Case 2 Passed" if response2 == "No relevant legal documents found. Please refine your query." else "‚ùå Test Case 2 Failed")

    # Test Case 3: Invalid Context Retrieval
    query3 = "What are the labor laws in India?"
    context_docs3 = ["", " ", None]
    
    response3 = chatbot.generate_response(query3, context_docs3)
    print("\n‚úÖ Test Case 3 Passed" if response3 == "Error: Retrieved context is empty or invalid." else "‚ùå Test Case 3 Failed")

    # Test Case 4: OpenRouter API Failure Simulation
    query4 = "What is the penalty for cyber fraud?"
    context_docs4 = [
        "Section 66C of the IT Act prescribes imprisonment up to three years and a fine for identity theft."
    ]
    
    chatbot.api_url = "https://invalid-url.com/api/v1/chat/completions"  # Simulating API failure
    response4 = chatbot.generate_response(query4, context_docs4)
    print("\n‚úÖ Test Case 4 Passed" if "API request failed" in response4 else "‚ùå Test Case 4 Failed")


if __name__ == "__main__":
    print("Choose an option:")
    print("1Ô∏è‚É£ Run chatbot interactively")
    print("2Ô∏è‚É£ Run test cases")

    choice = input("\nEnter your choice (1 or 2): ")

    if choice == "1":
        interactive_chat()
    elif choice == "2":
        test_chatbot()
    else:
        print("\n‚ùå Invalid choice. Exiting.")



==================================================
File: I:\Constitution-AI\backend\config.py
==================================================

from pathlib import Path

BASE_DIR = Path(__file__).parent
DATA_DIR = BASE_DIR / "data"
DOCUMENTS_DIR = DATA_DIR / "documents"
IMAGES_DIR = DOCUMENTS_DIR / "images"


==================================================
File: I:\Constitution-AI\backend\document_processor.py
==================================================

import io
import pymupdf
import docx
import easyocr
from config import DOCUMENTS_DIR
import uuid

class DocumentProcessor:
    """Handles parsing and text extraction from various document types"""
    @staticmethod
    def extract_text_from_pdf(pdf_file):
        """Extract text from PDF files"""
        doc = pymupdf.open(stream=pdf_file, filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()
        return text

    @staticmethod
    def extract_text_from_docx(docx_file):
        """Extract text from DOCX files"""
        doc = docx.Document(docx_file)
        return "\n".join([para.text for para in doc.paragraphs])

    @staticmethod
    def extract_text_from_image(image_file):
        """Extract text from images using OCR"""
        reader = easyocr.Reader(['en'])  # English OCR
        results = reader.readtext(image_file)
        return " ".join([result[1] for result in results])

    @classmethod
    def process_document(cls, file, file_type):
        file_path = DOCUMENTS_DIR / f"doc_{uuid.uuid4()}.{file_type}"
        """Process document based on file type"""
        type_map = {
            'pdf': cls.extract_text_from_pdf,
            'docx': cls.extract_text_from_docx, 
            'image': cls.extract_text_from_image
        }
        
        if file_type not in type_map:
            raise ValueError(f"Unsupported file type: {file_type}")
        
        return type_map[file_type](file)


==================================================
File: I:\Constitution-AI\backend\main.py
==================================================

import uvicorn
from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from typing import List, Optional
from config import DOCUMENTS_DIR

from document_processor import DocumentProcessor
from chatbot import LegalRAGChatbot

app = FastAPI(title="Legal RAG Chatbot")

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

chatbot = LegalRAGChatbot()

@app.post("/upload-knowledge-base")
async def upload_knowledge_base(files: List[UploadFile] = File(...)):
    """Upload and process documents for knowledge base"""
    processed_texts = []
    for file in files:
        file_path = DOCUMENTS_DIR / file.filename
        file_content = await file.read()
        file_type = file.filename.split('.')[-1].lower()
        try:
            text = DocumentProcessor.process_document(file_content, file_type)
            processed_texts.append(text)
        except ValueError as e:
            raise HTTPException(status_code=400, detail=str(e))
    
    # Add documents to vector store
    chatbot.vector_store.add_documents(processed_texts)
    return {"status": "Knowledge base updated", "documents_processed": len(processed_texts)}

@app.post("/chat")
async def chat_endpoint(query: str, context_file: Optional[UploadFile] = File(None)):
    """Main chat endpoint with optional context file"""
    # Process context file if provided
    context_texts = []
    if context_file:
        file_content = await context_file.read()
        file_type = context_file.filename.split('.')[-1].lower()
        context_text = DocumentProcessor.process_document(file_content, file_type)
        context_texts.append(context_text)
    
    # Retrieve relevant documents from vector store
    retrieved_docs = chatbot.vector_store.search(query)
    
    # Combine context and retrieved docs
    all_context = context_texts + retrieved_docs
    
    # Generate response
    response = chatbot.generate_response(query, all_context)
    
    return {"response": response}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)


==================================================
File: I:\Constitution-AI\backend\structure.py
==================================================

import os
from pathlib import Path
import argparse

def generate_tree(root_path, output_file="directory_structure.txt", ignore_patterns=None):
    """
    Generate a tree structure of the directory and save it to a file
    
    Args:
        root_path (str): Path to the root directory
        output_file (str): Name of the output file
        ignore_patterns (list): List of patterns to ignore (e.g., ['.git', '__pycache__', '*.pyc'])
    """
    if ignore_patterns is None:
        ignore_patterns = ['.git', '__pycache__', '*.pyc', '.env', '.venv', 'venv', 'env']
    
    def should_ignore(path):
        path_str = str(path)
        return any(
            ignored in path_str or 
            (ignored.startswith('*.') and path_str.endswith(ignored[1:]))
            for ignored in ignore_patterns
        )
    
    def get_tree(directory, prefix=""):
        """Recursively generate tree structure"""
        directory = Path(directory)
        trees = []
        
        # Get directories and files separately and sort them
        entries = list(directory.iterdir())
        dirs = sorted([d for d in entries if d.is_dir() and not should_ignore(d)])
        files = sorted([f for f in entries if f.is_file() and not should_ignore(f)])
        
        # Process all entries
        entries = dirs + files
        for i, entry in enumerate(entries):
            is_last = i == len(entries) - 1
            current_prefix = "‚îî‚îÄ‚îÄ " if is_last else "‚îú‚îÄ‚îÄ "
            
            # Add the current entry
            trees.append(f"{prefix}{current_prefix}{entry.name}")
            
            # If it's a directory, recursively process its contents
            if entry.is_dir() and not should_ignore(entry):
                next_prefix = prefix + ("    " if is_last else "‚îÇ   ")
                trees.extend(get_tree(entry, next_prefix))
        
        return trees

    # Generate the tree structure
    tree_structure = ["." + os.sep + os.path.basename(root_path)]
    tree_structure.extend(get_tree(root_path))
    
    # Write to file
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(tree_structure))
        
    return tree_structure

def main():
    parser = argparse.ArgumentParser(description='Generate directory structure tree')
    parser.add_argument('root_path', help='Root directory path')
    parser.add_argument('--output', '-o', default='directory_structure.txt',
                      help='Output file name (default: directory_structure.txt)')
    parser.add_argument('--ignore', '-i', nargs='+', 
                      help='Additional patterns to ignore (e.g., node_modules dist)')
    
    args = parser.parse_args()
    
    # Combine default ignore patterns with user-provided ones
    ignore_patterns = ['.git', '__pycache__', '*.pyc', '.env', '.venv', 'venv', 'env']
    if args.ignore:
        ignore_patterns.extend(args.ignore)
    
    try:
        tree = generate_tree(args.root_path, args.output, ignore_patterns)
        print(f"\nDirectory structure has been saved to {args.output}")
        print("\nStructure preview:")
        print('\n'.join(tree[:10] + ['...'] if len(tree) > 10 else tree))
    except Exception as e:
        print(f"Error: {str(e)}")

if __name__ == "__main__":
    main()


==================================================
File: I:\Constitution-AI\backend\vector_store.py
==================================================

import faiss
import numpy as np
import pickle
from pathlib import Path
from sentence_transformers import SentenceTransformer
from config import DATA_DIR

class VectorStoreManager:
    """Manages Faiss vector store for document embeddings with persistence"""
    def __init__(self, model_name='all-MiniLM-L6-v2'):
        self.index_path = DATA_DIR / "faiss_index"
        self.docs_path = DATA_DIR / "document_texts.pkl"
        self.embedding_model = SentenceTransformer(model_name)
        
        # Create data directory if it doesn't exist
        DATA_DIR.mkdir(parents=True, exist_ok=True)
        
        # Initialize or load existing index and documents
        self.index = None
        self.document_texts = []
        self.load_or_initialize()

    def load_or_initialize(self):
        """Load existing index and documents or initialize new ones"""
        try:
            if self.index_path.exists() and self.docs_path.exists():
                # Load the FAISS index
                self.index = faiss.read_index(str(self.index_path))
                
                # Load the document texts
                with open(self.docs_path, 'rb') as f:
                    self.document_texts = pickle.load(f)
                print(f"Loaded {len(self.document_texts)} documents from existing knowledge base")
            else:
                # Initialize new index
                self.index = faiss.IndexFlatL2(self.embedding_model.get_sentence_embedding_dimension())
                self.document_texts = []
                print("Initialized new knowledge base")
        except Exception as e:
            print(f"Error loading knowledge base: {str(e)}")
            # Initialize new index if loading fails
            self.index = faiss.IndexFlatL2(self.embedding_model.get_sentence_embedding_dimension())
            self.document_texts = []

    def save(self):
        """Save the current index and documents to disk"""
        try:
            # Save the FAISS index
            faiss.write_index(self.index, str(self.index_path))
            
            # Save the document texts
            with open(self.docs_path, 'wb') as f:
                pickle.dump(self.document_texts, f)
            
            print(f"Saved {len(self.document_texts)} documents to knowledge base")
        except Exception as e:
            print(f"Error saving knowledge base: {str(e)}")

    def add_documents(self, documents):
        """Add documents to vector store and save"""
        if not documents:
            return
        
        embeddings = self.embedding_model.encode(documents)
        self.index.add(embeddings)
        self.document_texts.extend(documents)
        
        # Save after adding new documents
        self.save()

    def search(self, query, top_k=3):
        """Retrieve similar documents"""
        if not self.document_texts:
            return []
            
        if self.index.ntotal == 0:
            return []
            
        try:
            query_embedding = self.embedding_model.encode([query])
            distances, indices = self.index.search(query_embedding, min(top_k, self.index.ntotal))
            return [self.document_texts[i] for i in indices[0] if i < len(self.document_texts)]
        except Exception as e:
            print(f"Error during vector search: {str(e)}")
            return []

    def get_document_count(self):
        """Return the number of documents in the store"""
        return len(self.document_texts)

    def clear(self):
        """Clear the knowledge base"""
        self.index = faiss.IndexFlatL2(self.embedding_model.get_sentence_embedding_dimension())
        self.document_texts = []
        
        # Remove saved files
        if self.index_path.exists():
            self.index_path.unlink()
        if self.docs_path.exists():
            self.docs_path.unlink()

